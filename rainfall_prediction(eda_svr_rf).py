# -*- coding: utf-8 -*-
"""Rainfall prediction(EDA_SVR_RF).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LBdy9ET1RmJ4aGjaNAFEGLRejKZt_Ltt

Loading libraries
"""

import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from sklearn.preprocessing import StandardScaler
import seaborn as sns
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

"""Downloading the dataset"""

pip install opendatasets --upgrade --quiet

import opendatasets as od

download_url = 'https://www.kaggle.com/datasets/josephw20/uk-met-office-weather-data'

od.download(download_url)

"""Loading the dataset"""

data_filename="/content/uk-met-office-weather-data/MET Office Weather Data.csv"

df=pd.read_csv(data_filename)

"""Exploratory data analysis"""

pd.set_option('display.max_row', None)

df.head()

df.shape

df.info()

df.describe()

for features in df.columns:
  print(df[features].unique())

"""Searching for missing values in the dataset


"""

df.isnull().sum()

[f for f in df.columns if df[f].isnull().sum()>0]

sns.heatmap(df.isnull(), yticklabels=False, cbar=False, cmap="viridis")
# plt.savefig('/content/missing.png')

for features in df.columns:
  print(features,'contains: ', df[features].isnull().sum()/len(df)*100, '% missing values')

"""Handling missing values"""

df=df.dropna(subset=['year', 'month'])
df.isnull().sum()

df.columns

cols_fill=['tmax', 'tmin', 'af', 'rain', 'sun']
for i in cols_fill:
  df[i].ffill(inplace=True)
  df[i].bfill(inplace=True)

df.isnull().sum()

"""checking correlation among features"""

plt.rcParams['figure.figsize']=[7, 4]
corr=df.corr()
sns.heatmap(corr, annot=True, fmt=".3f")
# plt.savefig('/content/corrplot.png')

"""Checking outliers"""

plt.rcParams['figure.figsize']=[8, 4]
sns.boxplot(df[['tmax', 'tmin', 'af', 'rain', 'sun']], orient='v')
# plt.savefig('/content/boxplot.png')

print(max(df['rain']))

plt.rcParams['figure.figsize']=[5, 5]
for i in df[['tmax', 'tmin', 'af', 'rain', 'sun']]:
  sns.distplot(df[i])
  plt.xlabel(i)
  plt.ylabel("Count")
  plt.title(i)
  plt.figure(figsize=(15,15))
  plt.show()
  # plt.savefig(f'/content/{i}.')

"""Handling outliers"""

for i in ['tmax', 'tmin', 'rain', 'sun']:
  upperValue=df[i].mean() + 3* df[i].std()
  lowerValue=df[i].mean() - 3* df[i].std()
  print(i, ":")
  print(lowerValue), print(upperValue),print(df[i].max()), print(df[i].min())
  print()
  df.loc[df[i]>=upperValue, i]=upperValue
  df.loc[df[i]<=lowerValue, i]=lowerValue


print()
iqr=df.af.quantile(0.75)-df.af.quantile(0.25)
lower_value=df['af'].quantile(0.25)-(iqr*3)
upper_value=df['af'].quantile(0.75)+(iqr*3)
print('af')
print(lower_value), print(upper_value), print(df['af'].max()), print(df['af'].min())
df.loc[df['af']>=upper_value, 'af']=upper_value
df.loc[df['af']<=lower_value, 'af']=lower_value

df.describe()

df.head()

"""Saving preprocessed dataset 2"""

df.to_csv('/content/uk_weather_data_preprocessed2.csv')

df=pd.read_csv('/content/uk_weather_data_preprocessed2.csv')
df.head()

df.year, df.month=df.year.astype(int), df.month.astype(int)
df['Date']=pd.to_datetime(df.year.astype(str)+'-'+df.month.astype(str))
df['Date2']=pd.to_datetime(df.year.astype(str)+'-'+df.month.astype(str))

"""```
Exploratory analysis of the feature 'year'.

Questions:
how many unique values in the year feature?
how many value count for each of the unique year?
what is the relation between year and station feature?
```
"""

print(len(df.year.unique()))
df.year.unique()

fig = plt.subplots(figsize=(20, 5))
sns.lineplot(x=df.year, y=df.year.value_counts(), data=df, marker='*', markerfacecolor='red', markersize=20).set(title='Years vs Value counts for each year', xlabel='Years', ylabel='Value counts')
sns.set_theme(style='dark', font_scale=3)
# plt.savefig('/content/year_value_counts.png')

df.year.value_counts()

plt.rcParams['figure.figsize'] = [30, 20]
sns.scatterplot(data=df, x="year", y="station")
# plt.savefig('/content/stationvsyear.png')

"""Time siries plotting

```
Exploratory data analysis of the target variable on time series plot.

Questions:
What kind of trends are the time series plot following?
Is there any seasonality present?
```
"""

df.index=df.Date
df.head()

df.rain.plot(figsize=(12, 4), xlim=['2000-01-01', '2020-12-01'], c='black', ls='--')
plt.ylabel('rainfall in mm')
# plt.savefig('/content/ts2000.png')

df.year.min()

df.rain.plot(figsize=(12, 4), xlim=['1975-01-01', '1999-12-01'], c='green', ls='--')
plt.ylabel('rainfall in mm')
# plt.savefig('/content/ts1975.png')

df.rain.plot(figsize=(12, 4), xlim=['1935-01-01', '1974-12-01'], c='blue', ls='--')
plt.ylabel('rainfall in mm')
# plt.savefig('/content/ts1935.png')

df.rain.plot(figsize=(12, 4), xlim=['1901-01-01', '1934-12-01'], c='brown', ls='--')
plt.ylabel('rainfall in mm')
# plt.savefig('/content/ts1901.png')

df.rain.plot(figsize=(12, 4), xlim=['1853-01-01', '1900-12-01'], c='red', ls='--')
plt.ylabel('rainfall in mm')
# plt.savefig('/content/ts1853.png')

"""```
Exploratory data analysis of the feature 'rainfall'.


Questions:
How the records look like for rainfall in a month?
In which month the rate of rainfall has got highest and lowest?
For which weather stations the rainfall was maximum regarding month count?
For which weather stations the ranfall was minimun regarding month count?
```
"""

df.rain.plot(kind='hist')
plt.ylabel('No. of records for stations in various year with month')
plt.xlabel('Rainfall amount in mm')
# plt.savefig('/content/histrain.png')

df.rain.describe()

hirec=df.iloc[np.where(df['rain']>=217.23)]
hirec['month'].value_counts()

plt.bar(hirec.station.unique(), hirec.station.value_counts(), color=['green', 'red', 'pink', 'blue', 'black', 'yellow', 'skyblue'])
plt.xticks(rotation=45)
plt.xlabel('Different weather stations in UK')
plt.ylabel('Counts of highest rainfall in a month of years')
# plt.savefig('/content/maxrainsta.png')

hirec=df.iloc[np.where(df['rain']<=0)]
hirec['month'].value_counts()

plt.bar(hirec.station.unique(), hirec.station.value_counts(), width=0.2 ,color=['black', 'yellow', 'skyblue', 'green', 'red', 'pink', 'blue'])
plt.xticks(rotation=45)
plt.xlabel('Different weather stations in UK')
plt.ylabel('Counts of lowest rainfall in a month of years')
# plt.savefig('/content/minrainsta.png')

"""```
Exploratory data analysis of the feature 'station'.

Questions:
How many unique weather stations are in the dataset?
What are percentages of stations used for different dates?
What are the stations have got rainfall less equal 10 mm?
What are the stations have got rainfall greater equal 200 mm?

What was the condition of rainfall after the year 2000?
What was the condition of rainfall from year 1975 to 1999?
What was the condition of rainfall before the year 1975?
```
"""

print(len(df.station.unique()))

plt.pie(df.station.value_counts(), labels=df.station.unique(), autopct='%.3f%%', radius=1.3)
# plt.savefig('/content/stationpercen.png')

pd.set_option('display.max_row', None)
df[['station', 'Date2', 'rain']]

rain10=df.loc[df.rain<=10]
rain200=df.loc[df.rain>=200]
print(len(rain10.station.unique()))
print(len(rain200.station.unique()))

rain2000=df.iloc[np.where(df.year>=2000)]
rain2000['rain'].describe()

rain7599=df.loc[(df['year']>=1975) & (df['year']<=1999)]
rain7599['rain'].describe()

rain1974=df.loc[(df['year']<=1975)]
rain1974['rain'].describe()

"""Observing the feature variables 'tmax', 'tmin', 'af', and 'sun' using histogram"""

for i in ['tmax', 'tmin', 'af', 'sun']:
  plt.hist(df[i])
  plt.xlabel('The feature'+ ' '+i)
  plt.ylabel('No. of records')
  # plt.savefig('/content/hist'+i+'.png')
  plt.show()

"""Converting categorical variable 'station' to numeric"""

df.reset_index(drop=True, inplace=True)
df=pd.get_dummies(df, columns=['station'])
df.head()

"""Saving uk_weather_data_preprocessed1"""

df.to_csv('/content/uk_weather_data_preprocessed1.csv')

"""Model training and prediction part for pre-processed dataset version 1"""

pdf=pd.read_csv('/content/uk_weather_data_preprocessed1.csv')
pdf.head()

pdf.columns

pdf_cols=['tmax', 'tmin', 'af', 'sun', 'station_aberporth', 'station_armagh',
       'station_ballypatrick', 'station_bradford', 'station_braemar',
       'station_camborne', 'station_cambridge', 'station_cardiff',
       'station_chivenor', 'station_cwmystwyth', 'station_dunstaffnage',
       'station_durham', 'station_eastbourne', 'station_eskdalemuir',
       'station_heathrow', 'station_hurn', 'station_lerwick',
       'station_leuchars', 'station_lowestoft', 'station_manston',
       'station_nairn', 'station_newtonrigg', 'station_oxford',
       'station_paisley', 'station_ringway', 'station_rossonwye',
       'station_shawbury', 'station_sheffield', 'station_southampton',
       'station_stornoway', 'station_tiree', 'station_valley',
       'station_waddington', 'station_whitby', 'station_wickairport',
       'station_yeovilton']
x=pdf[pdf_cols]
y=pdf['rain']
y

x.head()

"""Splitting data into train and test and Scaling"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.33,random_state=42)

scaler=StandardScaler()
scaler.fit(X_train)
scaled_trainx=scaler.transform(X_train)
scaled_testx=scaler.transform(X_test)

"""Using first model support vector regressor (SVR)"""

from sklearn.svm import SVR
from sklearn.model_selection import GridSearchCV


# parameters={
#             'kernel': ['rbf', 'sigmoid', 'poly'],
#             'C':[1.5, 10],'gamma': [1e-7, 1e-4],'epsilon':[0.1,0.2,0.5,0.3]
#             }

# svrModel=GridSearchCV(SVR(), parameters)
# svrModel.fit(scaledsvr_trainx, y_train)
# svrModel.best_params_


svr=SVR(kernel='rbf', gamma=1, epsilon=0.01)
svrModel=svr.fit(scaled_trainx, y_train)

svrypred=svrModel.predict(scaled_testx)

print(mean_absolute_error(y_test, svrypred))
print(mean_squared_error(y_test, svrypred))
print(r2_score(y_test, svrypred))

Adj_r2 = 1 - (1-r2_score(y_test, svrypred)) * (len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)
print(Adj_r2)

plt.rcParams['figure.figsize']=[10, 5]
plt.plot(y_test, label='y_test')
plt.plot(svrypred, label='svrypred')
plt.legend()

test_result = pd.DataFrame(data={'Predictions':svrypred, 'Actuals':y_test})
test_result

"""Using second model Random forest"""

from sklearn.ensemble import RandomForestRegressor
rfr=RandomForestRegressor()
rfrModel=rfr.fit(scaled_trainx, y_train)

rfrypred=rfrModel.predict(scaled_testx)

print(mean_absolute_error(y_test, rfrypred))
print(mean_squared_error(y_test, rfrypred))
print(r2_score(y_test, rfrypred))

Adj_r2 = 1 - (1-r2_score(y_test, rfrypred)) * (len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)
print(Adj_r2)

plt.rcParams['figure.figsize']=[10, 5]
plt.plot(y_test, label='y_test')
plt.plot(rfrypred, label='rfrypred')
plt.legend()

rfrtest_result = pd.DataFrame(data={'Predictions':rfrypred, 'Actuals':y_test})
rfrtest_result

